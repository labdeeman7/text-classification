{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text+Classification+using+python,+scikit+and+nltk.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "IAiJqK7bJUgX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7320c53b-c145-4983-b4f1-fe6cd7193a85"
      },
      "cell_type": "code",
      "source": [
        "#Loading the data set - training data.\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "twenty_train = fetch_20newsgroups(subset='train', shuffle=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nHy1vI86JUgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "a1424412-24c1-43ac-d48a-21e55b63c3f3"
      },
      "cell_type": "code",
      "source": [
        "# You can check the target names (categories) and some data files by following commands.\n",
        "twenty_train.target_names #prints all the categories"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "jnjdSNojJUgk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e400a422-e0a5-4a26-ffca-988d9a1015bb"
      },
      "cell_type": "code",
      "source": [
        "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3])) #prints first line of the first data file"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: lerxst@wam.umd.edu (where's my thing)\n",
            "Subject: WHAT car is this!?\n",
            "Nntp-Posting-Host: rac3.wam.umd.edu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lLZjYiExI_bw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "8b7c91f2-55ab-4ece-aad5-0849f1af65b2"
      },
      "cell_type": "code",
      "source": [
        "twenty_train.filenames[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['/root/scikit_learn_data/20news_home/20news-bydate-train/rec.autos/102994',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51861',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/51879',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.graphics/38242',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.space/60880',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/talk.politics.guns/54525',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/sci.med/58080',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.ibm.pc.hardware/60249',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.os.ms-windows.misc/10008',\n",
              "       '/root/scikit_learn_data/20news_home/20news-bydate-train/comp.sys.mac.hardware/50502'],\n",
              "      dtype='|S86')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "JugMKd_VJUgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d26c1bef-f797-4edd-c78b-7bd11119f8e0"
      },
      "cell_type": "code",
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect = CountVectorizer()\n",
        "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "3c6uFa0_JUgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e3e6913-54ad-4950-e4ee-d75c0ddc1c7d"
      },
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "H18SJooTJUgy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Machine Learning\n",
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf = clf.fit(X_train_tfidf, twenty_train.target)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iE62Gqu1JUg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Building a pipeline: We can write less code and do all of the above, by building a pipeline as follows:\n",
        "# The names â€˜vectâ€™ , â€˜tfidfâ€™ and â€˜clfâ€™ are arbitrary but will be used later.\n",
        "# We will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB(alpha=.01))])\n",
        "\n",
        "text_clf = text_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XquEDHXjSvsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0811d36e-bcbb-48a5-809f-bf59514258c4"
      },
      "cell_type": "code",
      "source": [
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "twenty_test = fetch_20newsgroups(subset='test', shuffle=True)\n",
        "predicted = text_clf.predict(twenty_test.data)\n",
        "np.mean(predicted == twenty_test.target)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8352363250132767"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "9DXadBh9SBEn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ce79bb42-2a98-4d77-bd0b-25985443029d"
      },
      "cell_type": "code",
      "source": [
        "#using the example from sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "vectors.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11314, 130107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "fXmvz--_QsIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "58ccdbf2-62a9-4445-b1b0-1c9a88a90dc6"
      },
      "cell_type": "code",
      "source": [
        "#using the example from sklearn\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "clf = MultinomialNB(alpha=.01)\n",
        "clf.fit(vectors, newsgroups_train.target)\n",
        "\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')\n",
        "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
        "\n",
        "pred = clf.predict(vectors_test)\n",
        "np.mean(pred == newsgroups_test.target)\n",
        "metrics.f1_score(newsgroups_test.target, pred, average='macro')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8290659644474043"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "LdZf9EopJUg-",
        "colab_type": "code",
        "colab": {},
        "outputId": "aee9b452-6764-4c37-abfc-a84990defcb4"
      },
      "cell_type": "code",
      "source": [
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
        "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, n_iter=5, random_state=42))])\n",
        "\n",
        "text_clf_svm = text_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
        "np.mean(predicted_svm == twenty_test.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\javedsha\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82381837493361654"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "gKd4JjzQJUhC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Grid Search\n",
        "# Here, we are creating a list of parameters for which we would like to do performance tuning. \n",
        "# All the parameters name start with the classifier name (remember the arbitrary name we gave). \n",
        "# E.g. vect__ngram_range; here we are telling to use unigram and bigrams and choose the one which is optimal.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDsMS__hJUhG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Next, we create an instance of the grid search by passing the classifier, parameters \n",
        "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
        "\n",
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dcjIast6JUhK",
        "colab_type": "code",
        "colab": {},
        "outputId": "0b4326ec-6012-4eec-d055-4a8de8da4741"
      },
      "cell_type": "code",
      "source": [
        "# To see the best mean score and the params, run the following code\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "\n",
        "# Output for above should be: The accuracy has now increased to ~90.6% for the NB classifier (not so naive anymore! ðŸ˜„)\n",
        "# and the corresponding parameters are {â€˜clf__alphaâ€™: 0.01, â€˜tfidf__use_idfâ€™: True, â€˜vect__ngram_rangeâ€™: (1, 2)}."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__alpha': 0.01, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "XIdKLafkJUhP",
        "colab_type": "code",
        "colab": {},
        "outputId": "c527827c-6e8f-4eca-90ca-bec864149ba9"
      },
      "cell_type": "code",
      "source": [
        "# Similarly doing grid search for SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False),'clf-svm__alpha': (1e-2, 1e-3)}\n",
        "\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
        "gs_clf_svm = gs_clf_svm.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "\n",
        "gs_clf_svm.best_score_\n",
        "gs_clf_svm.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf-svm__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 2)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "z5rH4KvfJUhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# NLTK\n",
        "# Removing stop words\n",
        "from sklearn.pipeline import Pipeline\n",
        "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')), ('tfidf', TfidfTransformer()), \n",
        "                     ('clf', MultinomialNB())])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZUMdpL1nJUhZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "64b1cac6-ac1f-4e7a-cacd-b77f0c596e5c"
      },
      "cell_type": "code",
      "source": [
        "# Stemming Code\n",
        "\n",
        "import nltk\n",
        "nltk.download()\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "\n",
        "class StemmedCountVectorizer(CountVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
        "    \n",
        "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
        "\n",
        "text_mnb_stemmed = Pipeline([('vect', stemmed_count_vect), ('tfidf', TfidfTransformer()), \n",
        "                             ('mnb', MultinomialNB(fit_prior=False))])\n",
        "\n",
        "text_mnb_stemmed = text_mnb_stemmed.fit(twenty_train.data, twenty_train.target)\n",
        "\n",
        "predicted_mnb_stemmed = text_mnb_stemmed.predict(twenty_test.data)\n",
        "\n",
        "np.mean(predicted_mnb_stemmed == twenty_test.target)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.81678173127987252"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "KHypvX5TJUhe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}